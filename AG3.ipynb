{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0 - NaiveBayes - Classification - Syntehic Data.ipynb","provenance":[{"file_id":"1t2_gCaPq0n8IBy97O8HMmiHDGh_wXmOO","timestamp":1521481985334}],"collapsed_sections":[]},"kernelspec":{"name":"python37464bit59e23452f18a48559a01e43bee303f02","display_name":"Python 3.7.4 64-bit"},"metadata":{"interpreter":{"hash":"b82ecaaff3c245f5ab267cc94a5fe43d31888c53cf2a4b652d7bb486c58b7eaf"}}},"cells":[{"source":["# 06MBIG - Machine Learning  \n","## Álvaro González Rodríguez  \n","### 74746657S\n","\n","En este notebook se pretende devolver una solución al problema de la competición del Dengue de DrivenData.\n","(https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/).  \n","El objetivo es predecir los casos totales de dengue en los días especificados en el dataset *dengue_features_test.csv*.  \n","La puntuación mínima que debemos obtener es de MAE = 29.2764"],"cell_type":"markdown","metadata":{}},{"source":["---\n","# Actividad 3 - Optimización\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.decomposition import PCA\n","# from sklearn.linear_model import LinearRegression\n","# from sklearn.model_selection import TimeSeriesSplit, KFold\n","from sklearn.metrics import mean_absolute_error\n","# from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","# import matplotlib.pyplot as plt\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Cargamos los datos de la actividad 1\n","train = pd.read_csv('dengue_train.csv')\n","test = pd.read_csv('dengue_test.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Definimos dataset de Train, Test y separamos en variables dependientes e independiente.\n","X_train = train.drop('total_cases', axis=1)\n","X_test = test\n","y_train = train['total_cases']\n","\n","# Definimos transformador\n","transformer = MinMaxScaler(feature_range=[0,1]).fit(X_train)\n","\n","# # Normalizamos los datos:\n","X_train_norm = transformer.transform(X_train)\n","X_test_norm = transformer.transform(X_test)\n","\n","# Definimos transformador PCA con 4 componentes\n","pca = PCA(n_components=4)\n","\n","# # Reducimos dimensionalidad\n","X_train_norm_pca = pca.fit_transform(X_train_norm)\n","X_test_norm_pca = pca.transform(X_test_norm)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def report(results, n_top=3): # Función para mostrar resultados\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n","                  results['mean_test_score'][candidate],\n","                  results['std_test_score'][candidate]))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["param_dist = {\"n_estimators\": [16, 32], # Number of trees in random forest\n","              \"max_features\": ['auto', 'sqrt'], # Number of features to consider at every split\n","              \"max_depth\": [4,5,6], # Maximum number of levels in tree\n","              \"min_samples_split\": [2, 4, 6], #  Minimum number of samples required to split a node\n","              \"min_samples_leaf\": [8, 12, 16], # Minimum number of samples required at each leaf node\n","              \"bootstrap\": [True, False], # Method of selecting samples for training each tree\n","              \"criterion\": ['mae'],\n","              'n_jobs': [-1],\n","              'random_state': [23]\n","            }"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n","                                             criterion='mse', max_depth=None,\n","                                             max_features='auto',\n","                                             max_leaf_nodes=None,\n","                                             max_samples=None,\n","                                             min_impurity_decrease=0.0,\n","                                             min_impurity_split=None,\n","                                             min_samples_leaf=1,\n","                                             min_samples_split=2,\n","                                             min_weight_fraction_leaf=0.0,\n","                                             n_estimators=100, n_jobs=None,\n","                                             oob_score=False, rand...\n","                                             verbose=0, warm_start=False),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'bootstrap': [True, False], 'criterion': ['mae'],\n","                         'max_depth': [4, 5, 6],\n","                         'max_features': ['auto', 'sqrt'],\n","                         'min_samples_leaf': [8, 12, 16],\n","                         'min_samples_split': [2, 4, 6],\n","                         'n_estimators': [16, 32], 'n_jobs': [-1],\n","                         'random_state': [23]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=0)"]},"metadata":{},"execution_count":6}],"source":["model = RandomForestRegressor() \n","grid_regres = GridSearchCV(estimator = model,\n","                           param_grid= param_dist,\n","                           cv=5)\n","\n","# Fit the random search model\n","grid_regres.fit(X = X_train_norm_pca, \n","                y = y_train)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model with rank: 1\nMean validation score: -0.087 (std: 0.182)\nParameters: {'bootstrap': True, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 2, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\nModel with rank: 1\nMean validation score: -0.087 (std: 0.182)\nParameters: {'bootstrap': True, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 4, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\nModel with rank: 1\nMean validation score: -0.087 (std: 0.182)\nParameters: {'bootstrap': True, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 6, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\nModel with rank: 4\nMean validation score: -0.107 (std: 0.165)\nParameters: {'bootstrap': False, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 2, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\nModel with rank: 4\nMean validation score: -0.107 (std: 0.165)\nParameters: {'bootstrap': False, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 4, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\nModel with rank: 4\nMean validation score: -0.107 (std: 0.165)\nParameters: {'bootstrap': False, 'criterion': 'mae', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 16, 'min_samples_split': 6, 'n_estimators': 16, 'n_jobs': -1, 'random_state': 23}\n\n"]}],"source":["report(grid_regres.cv_results_, n_top = 5)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n","                      max_depth=4, max_features='sqrt', max_leaf_nodes=None,\n","                      max_samples=None, min_impurity_decrease=0.0,\n","                      min_impurity_split=None, min_samples_leaf=16,\n","                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n","                      n_estimators=16, n_jobs=-1, oob_score=False,\n","                      random_state=23, verbose=0, warm_start=False)"]},"metadata":{},"execution_count":11}],"source":["grid_regres.best_estimator_"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Escogemos el mejor estimador\n","best_grid = grid_regres.best_estimator_\n","\n","# Ajustamos el mejor estimador y predecimos\n","best_grid.fit(X = X_train_norm_pca,\n","              y = y_train)\n","\n","# Predecimos los valores de test de la competicion              \n","predictions = best_grid.predict(X = X_test_norm_pca).astype('int')\n","\n","# Convertimos a 0 los valores negativos\n","predictions[predictions<0] = 0\n","\n","# Guardamos los resultados en un DataFrame\n","results = pd.read_csv('./dengue_features_test.csv', usecols=['city', 'year', 'weekofyear'])\n","results['total_cases'] = predictions\n","\n","results.to_csv('RandomForestRegressor_GSCV_results.csv', index=False)"]},{"source":["## RandomSearch"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomizedSearchCV(cv=5, error_score=nan,\n","                   estimator=RandomForestRegressor(bootstrap=True,\n","                                                   ccp_alpha=0.0,\n","                                                   criterion='mse',\n","                                                   max_depth=None,\n","                                                   max_features='auto',\n","                                                   max_leaf_nodes=None,\n","                                                   max_samples=None,\n","                                                   min_impurity_decrease=0.0,\n","                                                   min_impurity_split=None,\n","                                                   min_samples_leaf=1,\n","                                                   min_samples_split=2,\n","                                                   min_weight_fraction_leaf=0.0,\n","                                                   n_estimators=100,\n","                                                   n_jobs=None, oob_score=Fals...\n","                   iid='deprecated', n_iter=100, n_jobs=-1,\n","                   param_distributions={'bootstrap': [True, False],\n","                                        'criterion': ['mae'],\n","                                        'max_depth': [4, 5, 6],\n","                                        'max_features': ['auto', 'sqrt'],\n","                                        'min_samples_leaf': [8, 12, 16],\n","                                        'min_samples_split': [2, 4, 6],\n","                                        'n_estimators': [16, 32],\n","                                        'n_jobs': [-1], 'random_state': [23]},\n","                   pre_dispatch='2*n_jobs', random_state=23, refit=True,\n","                   return_train_score=False, scoring=None, verbose=0)"]},"metadata":{},"execution_count":19}],"source":["model = RandomForestRegressor()\n","rnd_regres = RandomizedSearchCV(estimator = model,\n","                                param_distributions = param_dist, \n","                                n_iter = 100,\n","                                cv = 5,\n","                                random_state=23,\n","                                n_jobs = -1)\n","\n","# Fit the random search model\n","rnd_regres.fit(X = X_train_norm_pca, \n","               y = y_train)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model with rank: 1\nMean validation score: -0.087 (std: 0.182)\nParameters: {'random_state': 23, 'n_jobs': -1, 'n_estimators': 16, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'mae', 'bootstrap': True}\n\nModel with rank: 2\nMean validation score: -0.107 (std: 0.165)\nParameters: {'random_state': 23, 'n_jobs': -1, 'n_estimators': 16, 'min_samples_split': 4, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'mae', 'bootstrap': False}\n\nModel with rank: 2\nMean validation score: -0.107 (std: 0.165)\nParameters: {'random_state': 23, 'n_jobs': -1, 'n_estimators': 16, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'mae', 'bootstrap': False}\n\nModel with rank: 4\nMean validation score: -0.117 (std: 0.172)\nParameters: {'random_state': 23, 'n_jobs': -1, 'n_estimators': 16, 'min_samples_split': 2, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'mae', 'bootstrap': False}\n\nModel with rank: 4\nMean validation score: -0.117 (std: 0.172)\nParameters: {'random_state': 23, 'n_jobs': -1, 'n_estimators': 16, 'min_samples_split': 4, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'mae', 'bootstrap': False}\n\n"]}],"source":["report(rnd_regres.cv_results_, n_top = 5)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'random_state': 23,\n"," 'n_jobs': -1,\n"," 'n_estimators': 16,\n"," 'min_samples_split': 2,\n"," 'min_samples_leaf': 16,\n"," 'max_features': 'sqrt',\n"," 'max_depth': 4,\n"," 'criterion': 'mae',\n"," 'bootstrap': True}"]},"metadata":{},"execution_count":21}],"source":["rnd_regres.best_params_"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Escogemos el mejor estimador\n","best_random = rnd_regres.best_estimator_\n","\n","# Ajustamos el mejor estimador y predecimos\n","best_random.fit(X = X_train_norm_pca,\n","                y = y_train)\n","\n","# Predecimos los valores de test de la competicion              \n","predictions = best_random.predict(X = X_test_norm_pca).astype('int')\n","\n","# Convertimos a 0 los valores negativos\n","predictions[predictions<0] = 0\n","\n","# Guardamos los resultados en un DataFrame\n","results = pd.read_csv('./dengue_features_test.csv', usecols=['city', 'year', 'weekofyear'])\n","results['total_cases'] = predictions\n","\n","results.to_csv('RandomForestRegressor_RandomSearchCV_results.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}